{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "L57opLUDaL3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZGZM3gBZ5Jw",
        "outputId": "505d1999-0b26-46d7-8d0e-4b56efeeb1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of charcters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Build LLM From Scratch/text_preprocessing/the-verdict.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(f\"Total number of charcters: {len(raw_text)}\")\n",
        "print(f\"{raw_text[:99]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization using Regex (Extra)"
      ],
      "metadata": {
        "id": "EHYbTVJpfRnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "DKOwYozlcI5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tekenized = re.split(r\"([,.:;?!-()_\\'\\s]|--)\", raw_text)\n",
        "tekenized = [item for item in tekenized if item.strip()]\n",
        "print(len(tekenized))\n",
        "print(tekenized[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI8IAIYwoJBO",
        "outputId": "6de2e3ea-e3a2-4707-e4f3-afca9769f05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n",
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting tokens into tokens ids"
      ],
      "metadata": {
        "id": "PhDRAbYz3YPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a vocabulary that maps every token to unique integer\n",
        "\n",
        "all_words = sorted(set(tekenized))\n",
        "print(all_words)\n",
        "print(len(all_words))"
      ],
      "metadata": {
        "id": "Z9PRb38MiWnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ed48c0-1d44-480e-a557-eb0d5181879c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed', 'Devonshire', 'Don', 'Dubarry', 'Emperors', 'Florence', 'For', 'Gallery', 'Gideon', 'Gisburn', 'Gisburns', 'Grafton', 'Greek', 'Grindle', 'Grindles', 'HAD', 'Had', 'Hang', 'Has', 'He', 'Her', 'Hermia', 'His', 'How', 'I', 'If', 'In', 'It', 'Jack', 'Jove', 'Just', 'Lord', 'Made', 'Miss', 'Money', 'Monte', 'Moon-dancers', 'Mr', 'Mrs', 'My', 'Never', 'No', 'Now', 'Nutley', 'Of', 'Oh', 'On', 'Once', 'Only', 'Or', 'Perhaps', 'Poor', 'Professional', 'Renaissance', 'Rickham', 'Riviera', 'Rome', 'Russian', 'Sevres', 'She', 'Stroud', 'Strouds', 'Suddenly', 'That', 'The', 'Then', 'There', 'They', 'This', 'Those', 'Though', 'Thwing', 'Thwings', 'To', 'Usually', 'Venetian', 'Victor', 'Was', 'We', 'Well', 'What', 'When', 'Why', 'Yes', 'You', '_', 'a', 'abdication', 'able', 'about', 'above', 'abruptly', 'absolute', 'absorbed', 'absurdity', 'academic', 'accuse', 'accustomed', 'across', 'activity', 'add', 'added', 'admirers', 'adopted', 'adulation', 'advance', 'aesthetic', 'affect', 'afraid', 'after', 'afterward', 'again', 'ago', 'ah', 'air', 'alive', 'all', 'almost', 'alone', 'along', 'always', 'am', 'amazement', 'amid', 'among', 'amplest', 'amusing', 'an', 'and', 'another', 'answer', 'answered', 'any', 'anything', 'anywhere', 'apparent', 'apparently', 'appearance', 'appeared', 'appointed', 'are', 'arm', 'arm-chair', 'arm-chairs', 'arms', 'art', 'articles', 'artist', 'as', 'aside', 'asked', 'at', 'atmosphere', 'atom', 'attack', 'attention', 'attitude', 'audacities', 'away', 'awful', 'axioms', 'azaleas', 'back', 'background', 'balance', 'balancing', 'balustraded', 'basking', 'bath-rooms', 'be', 'beaming', 'bean-stalk', 'bear', 'beard', 'beauty', 'became', 'because', 'becoming', 'bed', 'been', 'before', 'began', 'begun', 'behind', 'being', 'believed', 'beneath', 'bespoke', 'better', 'between', 'big', 'bits', 'bitterness', 'blocked', 'born', 'borne', 'boudoir', 'bravura', 'break', 'breaking', 'breathing', 'bric-a-brac', 'briefly', 'brings', 'bronzes', 'brought', 'brown', 'brush', 'bull', 'business', 'but', 'buying', 'by', 'called', 'came', 'can', 'canvas', 'canvases', 'cards', 'care', 'career', 'caught', 'central', 'chair', 'chap', 'characteristic', 'charming', 'cheap', 'check', 'cheeks', 'chest', 'chimney-piece', 'chucked', 'cigar', 'cigarette', 'cigars', 'circulation', 'circumstance', 'circus-clown', 'claimed', 'clasping', 'clear', 'cleverer', 'close', 'clue', 'coat', 'collapsed', 'colour', 'come', 'comfortable', 'coming', 'companion', 'compared', 'complex', 'confident', 'congesting', 'conjugal', 'constraint', 'consummate', 'contended', 'continued', 'corner', 'corrected', 'could', 'couldn', 'count', 'countenance', 'couple', 'course', 'covered', 'craft', 'cried', 'crossed', 'crowned', 'crumbled', 'cry', 'cured', 'curiosity', 'curious', 'current', 'curtains', 'd', 'dabble', 'damask', 'dark', 'dashed', 'day', 'days', 'dead', 'deadening', 'dear', 'deep', 'deerhound', 'degree', 'delicate', 'demand', 'denied', 'deploring', 'deprecating', 'deprecatingly', 'desire', 'destroyed', 'destruction', 'desultory', 'detail', 'diagnosis', 'did', 'didn', 'died', 'dim', 'dimmest', 'dingy', 'dining-room', 'disarming', 'discovery', 'discrimination', 'discussion', 'disdain', 'disdained', 'disease', 'disguised', 'display', 'dissatisfied', 'distinguished', 'distract', 'divert', 'do', 'doesn', 'doing', 'domestic', 'don', 'done', 'donkey', 'down', 'dozen', 'dragged', 'drawing-room', 'drawing-rooms', 'drawn', 'dress-closets', 'drew', 'dropped', 'each', 'earth', 'ease', 'easel', 'easy', 'echoed', 'economy', 'effect', 'effects', 'efforts', 'egregious', 'eighteenth-century', 'elbow', 'elegant', 'else', 'embarrassed', 'enabled', 'end', 'endless', 'enjoy', 'enlightenment', 'enough', 'ensuing', 'equally', 'equanimity', 'escape', 'established', 'etching', 'even', 'event', 'ever', 'everlasting', 'every', 'exasperated', 'except', 'excuse', 'excusing', 'existed', 'expected', 'exquisite', 'exquisitely', 'extenuation', 'exterminating', 'extracting', 'eye', 'eyebrows', 'eyes', 'face', 'faces', 'fact', 'faded', 'failed', 'failure', 'fair', 'faith', 'false', 'familiar', 'famille-verte', 'fancy', 'fashionable', 'fate', 'feather', 'feet', 'fell', 'fellow', 'felt', 'few', 'fewer', 'finality', 'find', 'fingers', 'first', 'fit', 'fitting', 'five', 'flash', 'flashed', 'florid', 'flowers', 'fluently', 'flung', 'follow', 'followed', 'fond', 'footstep', 'for', 'forced', 'forcing', 'forehead', 'foreign', 'foreseen', 'forgive', 'forgotten', 'form', 'formed', 'forming', 'forward', 'fostered', 'found', 'foundations', 'fragment', 'fragments', 'frame', 'frames', 'frequently', 'friend', 'from', 'full', 'fullest', 'furiously', 'furrowed', 'garlanded', 'garlands', 'gave', 'genial', 'genius', 'gesture', 'get', 'getting', 'give', 'given', 'glad', 'glanced', 'glimpse', 'gloried', 'glory', 'go', 'going', 'gone', 'good', 'good-breeding', 'good-humoured', 'got', 'grace', 'gradually', 'gray', 'grayish', 'great', 'greatest', 'greatness', 'grew', 'groping', 'growing', 'had', 'hadn', 'hair', 'half', 'half-light', 'half-mechanically', 'hall', 'hand', 'hands', 'handsome', 'hanging', 'happen', 'happened', 'hard', 'hardly', 'has', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'height', 'her', 'here', 'hermit', 'herself', 'hesitations', 'hide', 'high', 'him', 'himself', 'hint', 'his', 'history', 'holding', 'home', 'honour', 'hooded', 'hostess', 'hot-house', 'hour', 'hours', 'house', 'how', 'hung', 'husband', 'idea', 'idle', 'idling', 'if', 'immediately', 'in', 'incense', 'indifferent', 'inevitable', 'inevitably', 'inflexible', 'insensible', 'insignificant', 'instinctively', 'instructive', 'interesting', 'into', 'ironic', 'irony', 'irrelevance', 'irrevocable', 'is', 'it', 'its', 'itself', 'jardiniere', 'jealousy', 'just', 'keep', 'kept', 'kind', 'knees', 'knew', 'know', 'known', 'laid', 'lair', 'landing', 'language', 'last', 'late', 'later', 'latter', 'laugh', 'laughed', 'lay', 'leading', 'lean', 'learned', 'least', 'leathery', 'leave', 'led', 'left', 'leisure', 'lends', 'lent', 'let', 'lies', 'life', 'life-likeness', 'lift', 'lifted', 'light', 'lightly', 'like', 'liked', 'line', 'lines', 'lingered', 'lips', 'lit', 'little', 'live', 'll', 'loathing', 'long', 'longed', 'longer', 'look', 'looked', 'looking', 'lose', 'loss', 'lounging', 'lovely', 'lucky', 'lump', 'luncheon-table', 'luxury', 'lying', 'made', 'make', 'man', 'manage', 'managed', 'mantel-piece', 'marble', 'married', 'may', 'me', 'meant', 'mediocrity', 'medium', 'mentioned', 'mere', 'merely', 'met', 'might', 'mighty', 'millionaire', 'mine', 'minute', 'minutes', 'mirrors', 'modest', 'modesty', 'moment', 'money', 'monumental', 'mood', 'morbidly', 'more', 'most', 'mourn', 'mourned', 'moustache', 'moved', 'much', 'muddling', 'multiplied', 'murmur', 'muscles', 'must', 'my', 'myself', 'mysterious', 'naive', 'near', 'nearly', 'negatived', 'nervous', 'nervousness', 'neutral', 'never', 'next', 'no', 'none', 'not', 'note', 'nothing', 'now', 'nymphs', 'oak', 'obituary', 'object', 'objects', 'occurred', 'oddly', 'of', 'off', 'often', 'oh', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'open', 'or', 'other', 'our', 'ourselves', 'out', 'outline', 'oval', 'over', 'own', 'packed', 'paid', 'paint', 'painted', 'painter', 'painting', 'pale', 'paled', 'palm-trees', 'panel', 'panelling', 'pardonable', 'pardoned', 'part', 'passages', 'passing', 'past', 'pastels', 'pathos', 'patient', 'people', 'perceptible', 'perfect', 'persistence', 'persuasively', 'phrase', 'picture', 'pictures', 'pines', 'pink', 'place', 'placed', 'plain', 'platitudes', 'pleased', 'pockets', 'point', 'poised', 'poor', 'portrait', 'posing', 'possessed', 'poverty', 'predicted', 'preliminary', 'presenting', 'prestidigitation', 'pretty', 'previous', 'price', 'pride', 'princely', 'prism', 'problem', 'proclaiming', 'prodigious', 'profusion', 'protest', 'prove', 'public', 'purblind', 'purely', 'pushed', 'put', 'qualities', 'quality', 'queerly', 'question', 'quickly', 'quietly', 'quite', 'quote', 'rain', 'raised', 'random', 'rather', 're', 'real', 'really', 'reared', 'reason', 'reassurance', 'recovering', 'recreated', 'reflected', 'reflection', 'regrets', 'relatively', 'remained', 'remember', 'reminded', 'repeating', 'represented', 'reproduction', 'resented', 'resolve', 'resources', 'rest', 'rich', 'ridiculous', 'robbed', 'romantic', 'room', 'rose', 'rs', 'rule', 'run', 's', 'said', 'same', 'satisfaction', 'savour', 'saw', 'say', 'saying', 'says', 'scorn', 'scornful', 'secret', 'see', 'seemed', 'seen', 'self-confident', 'send', 'sensation', 'sensitive', 'sent', 'serious', 'set', 'sex', 'shade', 'shaking', 'shall', 'she', 'shirked', 'short', 'should', 'shoulder', 'shoulders', 'show', 'showed', 'showy', 'shrug', 'shrugged', 'sight', 'sign', 'silent', 'silver', 'similar', 'simpleton', 'simplifications', 'simply', 'since', 'single', 'sitter', 'sitters', 'sketch', 'skill', 'slight', 'slightly', 'slowly', 'small', 'smile', 'smiling', 'sneer', 'so', 'solace', 'some', 'somebody', 'something', 'spacious', 'spaniel', 'speaking-tubes', 'speculations', 'spite', 'splash', 'square', 'stairs', 'stammer', 'stand', 'standing', 'started', 'stay', 'still', 'stocked', 'stood', 'stopped', 'stopping', 'straddling', 'straight', 'strain', 'straining', 'strange', 'straw', 'stream', 'stroke', 'strokes', 'strolled', 'strongest', 'strongly', 'struck', 'studio', 'stuff', 'subject', 'substantial', 'suburban', 'such', 'suddenly', 'suffered', 'sugar', 'suggested', 'sunburn', 'sunburnt', 'sunlit', 'superb', 'sure', 'surest', 'surface', 'surprise', 'surprised', 'surrounded', 'suspected', 'sweetly', 'sweetness', 'swelling', 'swept', 'swum', 't', 'table', 'take', 'taken', 'talking', 'tea', 'tears', 'technicalities', 'technique', 'tell', 'tells', 'tempting', 'terra-cotta', 'terrace', 'terraces', 'terribly', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'they', 'thin', 'thing', 'things', 'think', 'this', 'thither', 'those', 'though', 'thought', 'three', 'threshold', 'threw', 'through', 'throwing', 'tie', 'till', 'time', 'timorously', 'tinge', 'tips', 'tired', 'to', 'told', 'tone', 'tones', 'too', 'took', 'tottering', 'touched', 'toward', 'trace', 'trade', 'transmute', 'traps', 'travelled', 'tribute', 'tributes', 'tricks', 'tried', 'trouser-presses', 'true', 'truth', 'turned', 'twenty', 'twenty-four', 'twice', 'twirling', 'unaccountable', 'uncertain', 'under', 'underlay', 'underneath', 'understand', 'unexpected', 'untouched', 'unusual', 'up', 'up-stream', 'upon', 'upset', 'upstairs', 'us', 'used', 'usual', 'value', 'varnishing', 'vases', 've', 'veins', 'velveteen', 'very', 'villa', 'vindicated', 'virtuosity', 'vista', 'vocation', 'voice', 'wall', 'wander', 'want', 'wanted', 'wants', 'was', 'wasn', 'watched', 'watching', 'water-colour', 'waves', 'way', 'weekly', 'weeks', 'welcome', 'went', 'were', 'what', 'when', 'whenever', 'where', 'which', 'while', 'white', 'white-panelled', 'who', 'whole', 'whom', 'why', 'wide', 'widow', 'wife', 'wild', 'wincing', 'window-curtains', 'wish', 'with', 'without', 'wits', 'woman', 'women', 'won', 'wonder', 'wondered', 'word', 'work', 'working', 'worth', 'would', 'wouldn', 'year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself']\n",
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "print(len(all_words))\n",
        "\n",
        "vocab = {token: id for id, token in enumerate(all_words)}\n",
        "\n",
        "for i, item in enumerate(vocab.items()):\n",
        "    print(i+1, item)\n",
        "    if i>= 10:\n",
        "      break"
      ],
      "metadata": {
        "id": "TT7le_c45sDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc85d81b-eb3f-4651-dfb6-94bb6540b532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1132\n",
            "1 ('!', 0)\n",
            "2 ('\"', 1)\n",
            "3 (\"'\", 2)\n",
            "4 ('(', 3)\n",
            "5 (')', 4)\n",
            "6 (',', 5)\n",
            "7 ('--', 6)\n",
            "8 ('.', 7)\n",
            "9 (':', 8)\n",
            "10 (';', 9)\n",
            "11 ('?', 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[\"<|endoftext|>\"], vocab[\"<|unk|>\"]\n",
        "\n",
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrilH3RPvoXP",
        "outputId": "0ff6674b-633e-448c-cca3-4e88a5388a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a simple tokenizer class"
      ],
      "metadata": {
        "id": "FozuYDQ6Ehe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self, vocab: dict):\n",
        "        self.token_to_id = vocab\n",
        "        self.id_to_token = {id: token for token, id in vocab.items()}\n",
        "\n",
        "    def encode(self, txt: str):\n",
        "        tokenized = re.split(r\"([,.:;?!-()_\\'\\s]|--)\", txt)\n",
        "        tokenized = [item.strip() if item.strip() in self.token_to_id else \"<|unk|>\" for item in tokenized if item.strip()]\n",
        "        ids = [self.token_to_id[token] for token in tokenized]\n",
        "\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids: list):\n",
        "        txt = \" \".join([self.id_to_token[id] for id in ids])\n",
        "        txt = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', txt) # removes spaces before the specified punctuation\n",
        "\n",
        "        return txt"
      ],
      "metadata": {
        "id": "QPEjAXSlCdTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizer(vocab)"
      ],
      "metadata": {
        "id": "azSeurqDZpu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "encoding = tokenizer.encode(txt)\n",
        "print(encoding)\n",
        "print(tokenizer.decode(encoding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut8hKptyfZWE",
        "outputId": "20f4f69d-e567-4029-903f-7db38c8eb19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
            "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try on a text not contained on the training set\n",
        "\n",
        "new_txt = \"Hey! Did you praise Allah today for his grants?\"\n",
        "print(tokenizer.encode(new_txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWqSvGNXhQtW",
        "outputId": "9e9e75fe-17ac-4953-bf86-06a5aba7be24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1131, 0, 1131, 1126, 1131, 1131, 1131, 456, 549, 1131, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1 = \"O Allah! give me strength.\"\n",
        "txt2 = \"I have to be patient.\"\n",
        "new_txt = \" <|endoftext|> \".join((txt1, txt2))\n",
        "print(new_txt)"
      ],
      "metadata": {
        "id": "R4Ydcrj1nRuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36a5cf3-d6bf-4e5a-d86d-421cb3c8d4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Allah! give me strength. <|endoftext|> I have to be patient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_txt_ids = tokenizer.encode(new_txt)"
      ],
      "metadata": {
        "id": "ogk4HAS-BKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(new_txt_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AjRbH6ffC1UN",
        "outputId": "1aae1555-efc6-4983-dce9-c1bca1593c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|> <|unk|>! give me <|unk|>. <|endoftext|> I have to be patient.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPE"
      ],
      "metadata": {
        "id": "Fct1vF2qbWi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioAQfqa6DDny",
        "outputId": "73dc82b8-bf0c-498a-b9c1-669dbf41bfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "63hDv_tLbpPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfv8Bltjbp1V",
        "outputId": "d686a9dd-82be-4213-c904-f50331b4b3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "GeA9MLMeb9Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"I will apologize to my mother for my mistake. <|endoftext|> The king needs the queen to give him a massage.\"\n",
        "ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIHxcYozilI9",
        "outputId": "6aad1f7d-c67c-400b-81ac-e246b87562f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40, 481, 16521, 284, 616, 2802, 329, 616, 7457, 13, 220, 50256, 383, 5822, 2476, 262, 16599, 284, 1577, 683, 257, 26900, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghm_8h_btGdb",
        "outputId": "bfb728a9-14d1-475b-c23b-81842d6d170b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will apologize to my mother for my mistake. <|endoftext|> The king needs the queen to give him a massage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Akwirw ier\")"
      ],
      "metadata": {
        "id": "nvM6W4r_tk-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b83b04-0410-4c46-b402-433a91c54bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[33901, 86, 343, 86, 220, 959]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[tokenizer.decode([token]) for token in tokenizer.encode(\"Akwirw ier\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwsfzY8Cog5x",
        "outputId": "6d7b70ca-098c-4ba9-ff45-768aa0e54ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ak', 'w', 'ir', 'w', ' ', 'ier']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(\"Akwirw ier\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dVOnpgAspGWD",
        "outputId": "610fcc77-0374-44c0-9eb5-87cdcc6932ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akwirw ier'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Sampling"
      ],
      "metadata": {
        "id": "ewlg8QwOE-C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XbmYawmH2wc",
        "outputId": "89f5cf4b-79bf-4c2a-da1d-6cd9b84804cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Build LLM From Scratch/text_preprocessing/the-verdict.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
        "    txt = f.read()\n",
        "\n",
        "enc_txt = tokenizer.encode(txt)\n",
        "print(f\"Encoded Text Size: {len(enc_txt)}\")"
      ],
      "metadata": {
        "id": "B4l9rrYjpVR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3221c61-4962-4250-e8d4-3aec8accab1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text Size: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_txt[50:]"
      ],
      "metadata": {
        "id": "gLcbzr92I3W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYuizAW3NmZ8",
        "outputId": "06d2943e-c9ba-45c5-a7ab-86f9c7041e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y:      [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    target = enc_sample[i]\n",
        "    print(f\"{context} ----> {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk0-YgBPOkNl",
        "outputId": "ed0eb3e1-2451-438a-eeb3-fa77cf46656a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ----> 4920\n",
            "[290, 4920] ----> 2241\n",
            "[290, 4920, 2241] ----> 287\n",
            "[290, 4920, 2241, 287] ----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    target = enc_sample[i]\n",
        "    print(tokenizer.decode(context), \"----->\", tokenizer.decode([target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OEDw9nWjQnm",
        "outputId": "31ecc02c-1577-4b31-f6db-4ae8f04959f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ----->  established\n",
            " and established ----->  himself\n",
            " and established himself ----->  in\n",
            " and established himself in ----->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "fTyXQt5CjQla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_length, stride):\n",
        "            context = token_ids[i : i+max_length]\n",
        "            self.input_ids.append(torch.tensor(context))\n",
        "\n",
        "            target = token_ids[i+1 : i+max_length+1]\n",
        "            self.target_ids.append(torch.tensor(target))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "VZbpUltnssOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following function uses the GPTDatasetV1 to load the inputs in batches via PyTorch DataLoader\n",
        "\n",
        "def create_dataloader_v1(\n",
        "    txt,\n",
        "    batch_size = 4,\n",
        "    max_length = 256,\n",
        "    stride = 128,\n",
        "    shuffle = True,\n",
        "    drop_last = True,\n",
        "    num_workers = 0\n",
        "):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = shuffle,\n",
        "        drop_last = drop_last,\n",
        "        num_workers = num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "mNGs2IToSl3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Build LLM From Scratch/text_preprocessing/the-verdict.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_txt = f.read()"
      ],
      "metadata": {
        "id": "whyxMnViXjmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_0 = create_dataloader_v1(\n",
        "    txt = raw_txt,\n",
        "    batch_size = 1,\n",
        "    stride = 1,\n",
        "    shuffle = False,\n",
        "    max_length = 4\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader_0)\n",
        "\n",
        "first_batch = next(data_iter)\n",
        "\n",
        "print(first_batch)\n",
        "\n",
        "second_batch = next(data_iter)\n",
        "\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlp_90lbngfK",
        "outputId": "c9e104cd-cbfe-4e42-b5a6-735a1ceee758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_1 = create_dataloader_v1(\n",
        "    txt = raw_txt,\n",
        "    batch_size = 1,\n",
        "    max_length = 2,\n",
        "    stride = 2,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader_1)\n",
        "\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)\n",
        "\n",
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztVrtd_sqrU5",
        "outputId": "61d3af25-ce13-4810-aec7-d7e829022cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 40, 367]]), tensor([[ 367, 2885]])]\n",
            "[tensor([[2885, 1464]]), tensor([[1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_2 = create_dataloader_v1(\n",
        "    txt = raw_txt,\n",
        "    batch_size = 1,\n",
        "    max_length = 8,\n",
        "    stride = 2,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader_2)\n",
        "\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)\n",
        "\n",
        "second_batch = next(data_iter)\n",
        "print(second_batch)\n",
        "\n",
        "third_batch = next(data_iter)\n",
        "print(third_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6DpMS0VrkkP",
        "outputId": "b735e5ee-2015-4ea4-860b-a16d39237bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])]\n",
            "[tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]]), tensor([[ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])]\n",
            "[tensor([[ 1807,  3619,   402,   271, 10899,  2138,   257,  7026]]), tensor([[ 3619,   402,   271, 10899,  2138,   257,  7026, 15632]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Dataset and DataLoader (Extra)"
      ],
      "metadata": {
        "id": "bivHXI6F75-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.randn((5,2))\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.randn((2,2))\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "Qbs2dD1Yu4nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZASjPjLc8Fkc",
        "outputId": "4cb0b33d-82be-4648-f656-08c156333d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.2846, -1.1679],\n",
              "         [-1.8851, -1.2288],\n",
              "         [-0.8017, -1.1892],\n",
              "         [ 0.1706, -0.3006],\n",
              "         [ 1.2895,  0.5622]]),\n",
              " tensor([0, 0, 0, 1, 1]),\n",
              " tensor([[-0.0728, -0.9722],\n",
              "         [-0.6049, -0.4990]]),\n",
              " tensor([0, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "yrbGIn1O8kmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "r2ELU4hVBYaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "7qvWUzAuCEBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSKzu3kGJigI",
        "outputId": "71be6f17-a56e-4118-bf45-be98e70cd0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbwRCwCGKAgJ",
        "outputId": "f6f41a7d-e2f0-4263-8924-c1a5bc5d1cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7adec86d6d30>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset = train_ds,\n",
        "    batch_size = 2,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset = test_ds,\n",
        "    batch_size = 2,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "SjYlD0c2KEsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x,y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}: {x}, {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-aeeb3LTzE",
        "outputId": "7a8f895a-0880-412e-8430-6fcd68fd7859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 0.1706, -0.3006],\n",
            "        [-1.8851, -1.2288]]), tensor([1, 0])\n",
            "Batch 2: tensor([[-0.2846, -1.1679],\n",
            "        [-0.8017, -1.1892]]), tensor([0, 0])\n",
            "Batch 3: tensor([[1.2895, 0.5622]]), tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x,y) in enumerate(test_loader):\n",
        "    print(f\"Batch {idx+1}: {x}, {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7OoI8NtL-YI",
        "outputId": "b25a0221-0d5b-48fe-aa6e-b3407e31a652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-0.0728, -0.9722],\n",
            "        [-0.6049, -0.4990]]), tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset = train_ds,\n",
        "    shuffle = True,\n",
        "    batch_size = 2,\n",
        "    drop_last = True\n",
        ")"
      ],
      "metadata": {
        "id": "-2FBqwsEMCAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x,y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}: {x} {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_YZLTs_Q3oG",
        "outputId": "ce9fa92e-de61-46c7-dcf1-dd0a3a97f123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-0.8017, -1.1892],\n",
            "        [-1.8851, -1.2288]]) tensor([0, 0])\n",
            "Batch 2: tensor([[-0.2846, -1.1679],\n",
            "        [ 0.1706, -0.3006]]) tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader sampling with a a batch size greater than 1\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text,\n",
        "    batch_size = 8,\n",
        "    max_length = 4,\n",
        "    stride = 4,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "Jhn9IRCj8KuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(dataloader)\n",
        "\n",
        "inputs, targets = next(data_iter)\n",
        "\n",
        "print(f\"Inputs:\\n{inputs}\")\n",
        "print(f\"Targets:\\n{targets}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZzPp-vF-Xsg",
        "outputId": "3439bcd9-1cd1-44a0-ad96-4911a9eeb761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Targets:\n",
            "tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using a stride of 4 with a max_length of 4, assures no overlaps happen between batches.\n",
        "- Overlaps could increase overfitting.\n"
      ],
      "metadata": {
        "id": "TVgbQ47W-3FB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating token embeddings"
      ],
      "metadata": {
        "id": "GqM6TgYr_WVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converting token ids into embedding vectors is the last text preparation step for LLM training.\n",
        "> Reviewing the steps:\n",
        "raw_text -> tokenized_text -> token_ids -> token embeddings\n",
        "- Initially, we generate random values for the embedding vectors.\n",
        "- These random values will be waiting optimization through LLM training.\n",
        "- Continuous vector representation (embeddings) are necessary for training a neural network."
      ],
      "metadata": {
        "id": "cv5rrIdi_ko-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An illustration example of the process (for simplicity)\n",
        "# assume vocabulary = 6 words\n",
        "# asume embeddings size = 3\n",
        "# Instantiate the embedding layer using PyTorch\n",
        "\n",
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "\n",
        "# Create embedding layer\n",
        "\n",
        "vocab_size = 6\n",
        "emb_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "emb_layer = torch.nn.Embedding(vocab_size, emb_dim)"
      ],
      "metadata": {
        "id": "K3s9ayZA-vcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(emb_layer)\n",
        "print(emb_layer.weight)\n",
        "print(emb_layer.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ybg7ZRlB9C2",
        "outputId": "4c83a30e-49b9-4009-fb44-04546d219b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(6, 3)\n",
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
            "torch.Size([6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is one row for each token in a vocabulary of 6 tokens.\n",
        "- Each token embedding has 3 dimensions (columns).\n"
      ],
      "metadata": {
        "id": "r0j2iRL5HBG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(emb_layer(torch.tensor([3])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOY2q5i0Gc9s",
        "outputId": "73a4604d-b3d5-4368-bc87-f7b02199f193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This corresponds to the third index and the fourth row seen in the previous matrix.\n",
        "- This tells us that the embedding layer is just a lookup table.\n",
        "- Retreive a vector from the lookup table using a token id.\n",
        "- This embedding layer approach is a more efficient version of the one-hot encoding and matrix multiplication approach."
      ],
      "metadata": {
        "id": "px8qMKSEIy9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the embedding layer on the 4 input ids\n",
        "emb_layer(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_6cMgR5GlCv",
        "outputId": "9a62b271-c4ca-4ae5-b2f0-51108a54f284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2753, -0.2010, -0.1606],\n",
              "        [-0.4015,  0.9666, -1.1481],\n",
              "        [-2.8400, -0.7849, -1.4096],\n",
              "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Each id value in the input_ids corresponds to a row in the lookup table (the embedding weight matrix)."
      ],
      "metadata": {
        "id": "c4XLabpgPT53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding words' positions"
      ],
      "metadata": {
        "id": "vHrfZC3IXMLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Additional layer to add positional information for text tokens.\n",
        "  - Has the same dimension as the previous layer\n",
        "- The self-attention mechanism would have no clue about word positions or order without this layer.\n",
        "- A token id in the previous embedding layer would always map to the same vector regardless of where it appeared in the input text.\n",
        "- In principle, the deterministic, position-independent embedding of the token ID is good for reproducability purposes. But, as we still need the positional information of a token in an input sequence and since the self-attention mechanism itself is position-agnostic, we have to inject our model with this additional positional layer.\n",
        "- Categories of position-aware embeddings:\n",
        "  1. Relative positional embeddings\n",
        "    - Answers/learns: \"How far apart is the word from another?\"\n",
        "    - Generalizes well to inputs of varying lengths.\n",
        "  2. Absolute positional embeddings\n",
        "    - Answers/learns: \"At which exact position the word appear?\"\n",
        "    - Does not generalize well to inputs of varying lengths.\n",
        "- The two categories ensure that the model gives accurate and context-aware predictions.\n",
        "- The choice of the positional embedding layer type is dependent on your application and the nature of the data used.\n",
        "- GPT models considered optimizing the positional layer during the training process rather than keeping it fixed or predefined."
      ],
      "metadata": {
        "id": "fk0w3W3KXSbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with 256-dimensional vector representation\n",
        "# Use the earlier vocabulary created by the BPE tokenizer\n",
        "\n",
        "vocab_size = 50257\n",
        "out_dim = 256\n",
        "\n",
        "embed_layer = torch.nn.Embedding(vocab_size, out_dim)"
      ],
      "metadata": {
        "id": "lYm-qMUBGljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sample data from the previous dataloader.\n",
        "- Embed each token in each batch into a 256-dimensional vector.\n",
        "- The dimension of the resulted embedding matrix: 8 × 4 × 256."
      ],
      "metadata": {
        "id": "Uu34m6mCoR6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_txt,\n",
        "    batch_size = 8,\n",
        "    max_length = max_length,\n",
        "    stride = 4,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "\n",
        "inputs, targets = next(data_iter)\n",
        "\n",
        "print(f\"Token IDs:\\n{inputs}\\nInputs shape: {inputs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDF1Ajbgn0J2",
        "outputId": "8b15002f-a385-4347-f482-e4403dc67b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            "tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Inputs shape: torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Embed these token ids into 256-dimensional vectors (the positional layer)."
      ],
      "metadata": {
        "id": "5DG16aQjF8SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = embed_layer(inputs)\n",
        "token_embeddings, token_embeddings.shape"
      ],
      "metadata": {
        "id": "nMPVh2g0qS48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7aa3f4-5f15-45cd-da2b-afd996cdfac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.3045, -2.2610, -0.4094,  ..., -1.6522, -0.2868,  1.2438],\n",
              "          [-0.2460,  0.2528,  0.2237,  ..., -0.7093, -0.6564, -1.2014],\n",
              "          [ 0.4986,  0.1621,  0.6822,  ...,  1.1171,  0.2367,  0.2138],\n",
              "          [-0.5436,  0.6707,  2.0537,  ..., -0.6127,  0.5454, -0.9175]],\n",
              " \n",
              "         [[-0.4044,  0.3227,  1.0297,  ...,  0.0570,  0.7727, -0.0346],\n",
              "          [-0.2779,  0.7304,  2.0882,  ...,  1.0014,  0.1509, -0.5499],\n",
              "          [-1.4237,  0.5973, -1.3234,  ..., -0.4272,  1.0466, -0.1104],\n",
              "          [-1.5506,  0.1693,  1.4931,  ..., -0.3387, -1.0787, -1.2689]],\n",
              " \n",
              "         [[ 1.4963,  0.5346,  0.8751,  ...,  2.5655, -0.7914,  1.6417],\n",
              "          [-0.5089, -1.4528, -0.4107,  ...,  0.7509,  0.4721,  0.3420],\n",
              "          [ 0.0118, -1.0189,  0.1589,  ...,  0.5212, -0.2544,  0.9034],\n",
              "          [-0.6605,  0.8879, -0.3432,  ...,  0.0128,  0.4897, -0.2956]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ 1.2109, -1.1724, -1.9072,  ...,  0.6573, -2.3168,  2.6120],\n",
              "          [ 0.4538,  1.3213,  0.0283,  ..., -0.2926,  0.3914, -0.2848],\n",
              "          [ 1.7247, -0.6199, -1.1178,  ...,  0.2269, -0.6249, -0.0186],\n",
              "          [-1.3750,  0.4348,  1.0153,  ...,  1.8779, -0.9550,  0.2826]],\n",
              " \n",
              "         [[-0.2413,  1.6948,  0.3091,  ...,  0.7146,  0.7274, -0.7138],\n",
              "          [-1.2822, -1.6619,  0.5314,  ..., -0.7206, -1.5539, -0.1668],\n",
              "          [ 2.1356, -0.6274,  0.0305,  ...,  1.0674, -0.6086,  1.2898],\n",
              "          [-0.7850, -0.4496,  0.6611,  ..., -0.7056,  0.2797,  1.6684]],\n",
              " \n",
              "         [[ 2.1356, -0.6274,  0.0305,  ...,  1.0674, -0.6086,  1.2898],\n",
              "          [-1.3973,  0.0708,  0.8260,  ..., -1.9298, -1.6454, -1.0356],\n",
              "          [-0.7752,  1.3612, -2.0527,  ...,  0.1233,  0.0466,  0.1682],\n",
              "          [-0.4270, -2.8876, -1.3638,  ..., -0.4342, -0.1795,  1.0636]]],\n",
              "        grad_fn=<EmbeddingBackward0>),\n",
              " torch.Size([8, 4, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For the absolute positional embedding approach, we add another embedding layer with the same size."
      ],
      "metadata": {
        "id": "i2IXK61aJB0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "\n",
        "pos_layer = torch.nn.Embedding(context_length, out_dim)"
      ],
      "metadata": {
        "id": "zu196CtkHb4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_layer(torch.arange(context_length))\n",
        "pos_embeddings, pos_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob4zoVcAG-Lk",
        "outputId": "2f83b956-ff84-4e89-b5ad-dddab0690eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-2.3757,  0.3616,  1.6211,  ..., -0.6813, -1.1042, -0.5608],\n",
              "         [ 1.1531,  0.0796,  0.5718,  ...,  1.3845, -1.1687,  2.1513],\n",
              "         [ 0.2339, -0.5470,  0.7052,  ...,  0.1407, -1.9278, -1.4534],\n",
              "         [-0.2963, -0.2133,  0.5776,  ..., -0.0176,  0.8153, -1.4964]],\n",
              "        grad_fn=<EmbeddingBackward0>),\n",
              " torch.Size([4, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch.arange(context_length) is a placeholder vector contains a sequence of numbers 0, 1, .., up to the maximum input length.\n",
        "- The context_length represents the supported input size that the LLM reveives.\n",
        "- If the input text to the LLM is larger than the supported context length, it would be truncated.\n",
        "- We add the two seperate embeddings."
      ],
      "metadata": {
        "id": "VEoH5iFTLbc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "input_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2p8QlkVLEYB",
        "outputId": "5b34c910-c20c-4c30-dbdf-77beec411e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This is the final input that is ready to be passed to the transformer module of the LLM."
      ],
      "metadata": {
        "id": "-kAtVy_PQCj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "- For the text data to be compatible with NN, it must be transformed into numerical values in a continuous vector space (embeddings).\n",
        "- First step is tokenization. Tokenization can be character level or word level. The tokens are converted into token IDs followingly.\n",
        "- Some special tokens can be added to help the model handle some contexts like unknown words or boundary between unrelated texts.\n",
        "- BPE is a famous tokenization algorithm used by GPT-2 and GPT-3. It handles unknown words effeciently.\n",
        "- Through the sliding window technique, we can get input-target pairs from the tokenized data to train the LLM.\n",
        "\n",
        "- The embedding layers in the LLMs works as a lookup operation. For each token id, there is a corresponding continuous embedding vector.\n",
        "- A positional embedding layer is added at the end to give positional information."
      ],
      "metadata": {
        "id": "NyW3FHePpKyd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVvrfpPKLERb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8kg1EcrLEK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "durRVHTTK69X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wlWcKOknK5YG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}